{"task_id": "single_trivia_dev_6484", "answer": "Yoda", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "354.75778546712803", "gold_answers": "['Master Yoda', 'Star Wars/Yoda', 'Jedi Master Yoda', 'Mr Yoda', 'Yodaish', 'Do or do not, there is no try', 'Yoda']", "NoR_predicted_answer": "Yoda", "IRCoT_predicted_answer": "Yoda", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_4771", "answer": "Cardiff", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['City of Cardiff', 'County Borough of Cardiff', 'Caerdydd (city)', 'Caerdydd', 'Cardiff North (geographical area)', 'Trowbridge Primary School', 'The weather in Cardiff', 'Cardiff East (geographical area)', 'Cardiff West (geographical area)', 'East Cardiff', 'Cardff', 'Cardiff/Caerdydd', 'Cardiffians', 'Trowbridge Junior School', 'Cardiff South (geographical area)', 'Cardiff', 'UN/LOCODE:GBCDF', 'Trowbridge Infant School', 'Cardiff, Wales', '029', 'Caerdydd (county borough)']", "NoR_predicted_answer": "Cardiff", "IRCoT_predicted_answer": "Cardiff", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_squad_dev_486", "answer": "two", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['2']", "NoR_predicted_answer": "two", "IRCoT_predicted_answer": "2", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_squad_dev_3598", "answer": "two", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['two']", "NoR_predicted_answer": "two", "IRCoT_predicted_answer": "unanswerable", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "5ae39e9c5542990afbd1e195", "answer": "The Captain Matchbox Whoopee Band", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['The Captain Matchbox Whoopee Band']", "NoR_predicted_answer": "The Australian String Quartet", "IRCoT_predicted_answer": "The Captain Matchbox Whoopee Band", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5a7e04b05542995f4f40238a", "answer": "National League", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "425.70934256055364", "gold_answers": "['Vanarama']", "NoR_predicted_answer": "National League", "IRCoT_predicted_answer": "Vanarama", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_nq_dev_2922", "answer": "Neptune", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Neptune']", "NoR_predicted_answer": "Uranus", "IRCoT_predicted_answer": "Neptune", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_7689", "answer": "Nan Aye Khine", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "425.70934256055364", "gold_answers": "['CARL LEWIS', 'Carl Lewis', 'Frederick Carlton Lewis']", "NoR_predicted_answer": "Michael Johnson", "IRCoT_predicted_answer": "Nan Aye Khine", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "2hop__83489_747874", "answer": "Andy Murray", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Jamie Murray']", "NoR_predicted_answer": "Chris Gayle", "IRCoT_predicted_answer": "Andy Murray", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.5 count:1 accuracy:0.0"}
{"task_id": "02323884085611ebbd59ac1f6bf848b6", "answer": "no", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "496.66089965397924", "gold_answers": "['yes']", "NoR_predicted_answer": "no", "IRCoT_predicted_answer": "no", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "5ab9b7d555429970cfb8eb7a", "answer": "Lee Sung-kyung", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Henry Lau']", "NoR_predicted_answer": "Lee Sung-kyung", "IRCoT_predicted_answer": "Henry Lau", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "4c7a03560bdd11eba7f7acde48001122", "answer": "Beijing", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['Beijing']", "NoR_predicted_answer": "Beijing", "IRCoT_predicted_answer": "Beijing", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5ab32256554299233954ff22", "answer": "CEO", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['Chief Strategy Officer']", "NoR_predicted_answer": "CEO", "IRCoT_predicted_answer": "Chief Strategy Officer", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_squad_dev_4405", "answer": "Captain of the Yeomen of the Guard", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Benedict Arnold']", "NoR_predicted_answer": "John Hancock", "IRCoT_predicted_answer": "Captain of the Yeomen of the Guard", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "2hop__528263_865831", "answer": "Shelby County", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['Randall County']", "NoR_predicted_answer": "Shelby County", "IRCoT_predicted_answer": "Randall County", "NoR_evaluation_results": "em:0.0 f1:0.5 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_squad_dev_1294", "answer": "16th and 17th centuries", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['16th and 17th centuries']", "NoR_predicted_answer": "1868", "IRCoT_predicted_answer": "16th and 17th centuries", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5a8add4c5542992d82986fb4", "answer": "Mohamed Salah", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Daniel Sturridge']", "NoR_predicted_answer": "Mohamed Salah", "IRCoT_predicted_answer": "Daniel Sturridge", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "0745c7f20bdd11eba7f7acde48001122", "answer": "John Huston", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Mohsen Makhmalbaf']", "NoR_predicted_answer": "John Huston", "IRCoT_predicted_answer": "Juan Antonio Bardem", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "2hop__540035_113442", "answer": "November 27, 1939", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['13 August 1896']", "NoR_predicted_answer": "November 27, 1939", "IRCoT_predicted_answer": "13 August 1896", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5ee5d6ca08e811ebbda6ac1f6bf848b6", "answer": "paint", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "[\"My Wife'S Best Friend\"]", "NoR_predicted_answer": "My Wife's Best Friend", "IRCoT_predicted_answer": "My Wife's Best Friend", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_7410", "answer": "paint", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['Paintworks', 'PAINT', 'Self-leveling paint', 'Paint', 'Painted', 'Paints', 'Paintwork', 'Emulsion paint', 'Paints and coatings', 'Open time prolonger', 'Paint film', 'Paint chips', 'Chrome paint', 'Self-levelling paint', 'Paint chip']", "NoR_predicted_answer": "paint", "IRCoT_predicted_answer": "paints and wallpapers", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:0.0 f1:0.667 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_2834", "answer": "New York City", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Baghdad (Iraq)', 'Baghd\u0101d, Iraq', 'Baghdad Administrative divisions', 'Capital of Iraq', 'Baqdad', 'Bhagdad', 'Baghdad, Iraq', 'Bagdhad', 'Asia/Baghdad', 'Baghdad City', 'Baghdad', '89 official neighbourhoods', 'Ba\u0121d\u0101d', 'Baghd\u0101d', 'Bagdat', 'Bahgdad', 'Mama ayser center', '\u0628\u063a\u062f\u0627\u062f']", "NoR_predicted_answer": "New York City", "IRCoT_predicted_answer": "Kansas City", "NoR_evaluation_results": "em:0.0 f1:0.4 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.5 count:1 accuracy:0.0"}
{"task_id": "single_trivia_dev_1059", "answer": "Scotland", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['The Scottish Nation', 'Scotlander', 'Scotland', 'Northern Great Britain', 'Scot Land', 'Scottland', 'Scotlanders', 'Scotland, UK', \"Scotland's\", 'Scottish nation', 'North Great Britain', 'Autonomous Province of Scotland', 'Scottish Nation', 'Communications in Scotland', 'Maps of scotland', 'North of Great Britain', 'Scotia minor', 'Auld Country', 'Scotchland', 'H-Alba', 'SCOTLAND', 'East coast of Scotland']", "NoR_predicted_answer": "Scotland", "IRCoT_predicted_answer": "Scotland", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_nq_dev_3972", "answer": "Pink Floyd", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Pink Floyd']", "NoR_predicted_answer": "Pink Floyd", "IRCoT_predicted_answer": "Pink Floyd", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_nq_dev_1942", "answer": "Naggaroth", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "141.9031141868512", "gold_answers": "['Svartalfheim']", "NoR_predicted_answer": "in the Underdark", "IRCoT_predicted_answer": "Naggaroth", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "2hop__816977_6455", "answer": "Mozilla Firefox", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "141.9031141868512", "gold_answers": "['Firefox']", "NoR_predicted_answer": "Firefox", "IRCoT_predicted_answer": "Mozilla Firefox", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:0.0 f1:0.667 count:1 accuracy:1.0"}
{"task_id": "5ae70f4c5542991bbc9761b2", "answer": "Afghanistan", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Afghanistan']", "NoR_predicted_answer": "Afghanistan", "IRCoT_predicted_answer": "Afghanistan", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "8e85a6bd086311ebbd5eac1f6bf848b6", "answer": "Victor Chandler", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Victor Chandler']", "NoR_predicted_answer": "Victor Chandler", "IRCoT_predicted_answer": "Victor Chandler", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "172d29020bde11eba7f7acde48001122", "answer": "St. Peter's Church, Audley End", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "354.75778546712803", "gold_answers": "['Darley Abbey']", "NoR_predicted_answer": "St. Peter's Church, Audley End", "IRCoT_predicted_answer": "Hawarden Old Castle", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "2hop__53147_7298", "answer": "Billy Joel", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Michael Bubl\u00e9']", "NoR_predicted_answer": "Elton John", "IRCoT_predicted_answer": "Billy Joel", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "3441959e090f11ebbdadac1f6bf848b6", "answer": "Flirting In The Air", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Flirting In The Air']", "NoR_predicted_answer": "Flirting In The Air", "IRCoT_predicted_answer": "A Conspiracy of Faith", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "single_nq_dev_3518", "answer": "Mark Lawson", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Mark Lawson']", "NoR_predicted_answer": "Jason Priestley", "IRCoT_predicted_answer": "Mark Lawson", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "2hop__59612_42429", "answer": "1763", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['10 February 1763']", "NoR_predicted_answer": "1763", "IRCoT_predicted_answer": "1763", "NoR_evaluation_results": "em:0.0 f1:0.5 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.5 count:1 accuracy:0.0"}
{"task_id": "single_trivia_dev_3511", "answer": "Auguste Rodin", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Fran\u00e7ois Auguste Ren\u00e9 Rodin', 'August Rodin', 'Francois Auguste Rene Rodin', 'Pierre Auguste Rodin', 'Auguste Rodin Sculptor', 'Rodin', 'Fran\u00e7ois-Auguste-Ren\u00e9 Rodin', 'Auguste Rodin', 'Francois Auguste Ren\u00e9 Rodin', '\u0420\u043e\u0434\u0438\u043d', 'A Rodin', 'Rose Beuret', 'Francois-Auguste-Rene Rodin', 'Rose beuret', 'The Man with the Broken Nose']", "NoR_predicted_answer": "Auguste Rodin", "IRCoT_predicted_answer": "Auguste Rodin", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "a1f15751088e11ebbd70ac1f6bf848b6", "answer": "Two Cops", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['Never Too Young To Die']", "NoR_predicted_answer": "Two Cops", "IRCoT_predicted_answer": "Two Cops", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "single_nq_dev_537", "answer": "malice", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['actual malice']", "NoR_predicted_answer": "a causal link between the alleged infringement and the alleged copyright infringement", "IRCoT_predicted_answer": "malice", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.667 count:1 accuracy:0.0"}
{"task_id": "3hop1__545624_2053_52946", "answer": "NBC", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['February 7, 2018']", "NoR_predicted_answer": "January 1, 2018", "IRCoT_predicted_answer": "NBC", "NoR_evaluation_results": "em:0.0 f1:0.333 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "5a8b120755429949d91db4a4", "answer": "United States", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "212.85467128027682", "gold_answers": "['American']", "NoR_predicted_answer": "American", "IRCoT_predicted_answer": "United States", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "5ae13bca55429901ffe4ae17", "answer": "Jessy J", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "425.70934256055364", "gold_answers": "['Debbie Harry']", "NoR_predicted_answer": "Taylor Swift", "IRCoT_predicted_answer": "Jessy J", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "single_nq_dev_1666", "answer": "Bob Dylan", "complexity_label": "B", "NoR_time_taken": "0.705", "IRCoT_time_taken": "354.75778546712803", "gold_answers": "['Garth Brooks']", "NoR_predicted_answer": "Bob Dylan", "IRCoT_predicted_answer": "Garth Brooks", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_881", "answer": "adrenal gland", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Adrenal Gland', 'Suprarenals', 'Adrenal function', 'Glandula suprarenalis', 'Suprarenal bodies', 'Suprarenal glands', 'Adrenals', 'Adrenal Glands', 'Glandulae suprarenalis', 'Glandula adrenalis', 'Epinephric gland', 'Adrenal gland', 'Suprarenal Gland', 'Suprarenal gland', 'Adrenomedullary', 'Adrenal', 'Mammalian adrenal gland', 'Adrenal glands', 'Glandulae adrenalis']", "NoR_predicted_answer": "adrenal gland", "IRCoT_predicted_answer": "adrenal gland", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5ab7ba7555429928e1fe38b5", "answer": "James Mitchum", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['James Mitchum']", "NoR_predicted_answer": "John Wayne", "IRCoT_predicted_answer": "James Mitchum", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "0d118fb00bdb11eba7f7acde48001122", "answer": "unknown", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Westwood Village Memorial Park Cemetery']", "NoR_predicted_answer": "Mausoleum", "IRCoT_predicted_answer": "unknown", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "single_trivia_dev_184", "answer": "World War II", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['American occupation of Cuba (1898\u20131902)', 'SPanish-american war', 'Spanish-American-Cuban-Filipino War', 'The Spanish-American War', 'The spanish american war', 'Spanish-American war', 'The splendid little war', 'Spanish American War', 'Guerra de Cuba', 'The Spanish-Amercan War', 'Spanish-American War', 'Spanish-America War', 'Guerra hispano-estadounidense', 'American-Spanish War', 'Pacific Campaign (Spanish-American War)', 'Spainish-american war', 'Spanish American war', 'Hispano\u2013American War', 'Spanish \u2013 American War', 'Splendid little war', 'Spanish-American War of 1898', 'Pacific campaign (Spanish-American War)', 'Spanish\u2013American War', 'American spanish war', '1898 Spanish\u2013American War', 'Spanish/American War', 'Hispano-American War', 'Spanish-american war']", "NoR_predicted_answer": "World War II", "IRCoT_predicted_answer": "World War II", "NoR_evaluation_results": "em:0.0 f1:0.4 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.4 count:1 accuracy:0.0"}
{"task_id": "single_trivia_dev_7602", "answer": "Eritrea", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Administrative divisions of Eritrea', 'Eritrea', 'Erythraia', 'Iritriya', 'State of Eritrea', 'Eritria', 'Eriteria', 'Erithrea', 'Erythr\u00e9e', 'Eirtrea', '\u02beErtr\u0101', 'Dawlat Iritriy\u00e1', 'Eruthraia', 'ISO 3166-1:ER', 'Erythrea', 'Eritirea', 'Erythree', 'Eritreah', 'Hagere Ertra', 'Ertrea', 'Ertra']", "NoR_predicted_answer": "Eritrea", "IRCoT_predicted_answer": "Eritrea", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_trivia_dev_2993", "answer": "New Zealand", "complexity_label": "A", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['N Z', 'Nouvelle-Zelande', 'Kiwiland', \"New Zealand's\", 'New Zealand.', 'Nz', 'New Zealand,', 'NEW Z', 'N Zealand', 'NEW ZEALAND', 'New Zealend', 'Administrative divisions of new zealand', 'New Zaeland', 'N z', 'Kiwistan', 'Enzed', 'NewZealand', 'NZ', 'Name of New Zealand', 'Staten Landt', 'New+Zealand', 'NZL', 'Nu Tirani', 'Neo Zealand', 'ISO 3166-1:NZ', 'New Zealnd', 'AoTeAroa', 'Sheepland', 'Aotearoa / New Zealand', 'Subdivisions of New Zealand', 'Its got that new zeal', 'New Zealand', 'Newzealand', 'New Zeland', 'New-Zealand', 'New Zeeland', 'Administrative divisions of New Zealand', 'New Zealnad', 'Staten Land', 'N.Z.', 'Staaten land', 'New.Zealand', 'Mew Zealand', 'Maoriland', 'N. Zealand', 'Etymology of New Zealand', 'New Xealand', 'M\u0101oria', 'New zelanad', 'Niu Tireni', 'New zealand', 'New zeland', 'Nova Zeelandia', 'New zeeland']", "NoR_predicted_answer": "New Zealand", "IRCoT_predicted_answer": "New Zealand", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "2hop__503085_110222", "answer": "10 June 1819", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['10 June 1819']", "NoR_predicted_answer": "1832", "IRCoT_predicted_answer": "10 June 1819", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5a77727555429972597f1540", "answer": "Sarah Paulson", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "709.5155709342561", "gold_answers": "['Sarah Paulson']", "NoR_predicted_answer": "Sarah Paulson", "IRCoT_predicted_answer": "Sarah Paulson", "NoR_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "5ab27287554299722f9b4d2c", "answer": "The Game of Life", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "['The Game of Life']", "NoR_predicted_answer": "The History of the World", "IRCoT_predicted_answer": "The Game of Life", "NoR_evaluation_results": "em:0.0 f1:0.333 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:1.0 f1:1.0 count:1 accuracy:1.0"}
{"task_id": "single_squad_dev_234", "answer": "Fr\u00e9d\u00e9ric Chopin", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "567.6124567474048", "gold_answers": "['Alexander Glazunov.']", "NoR_predicted_answer": "George Sand", "IRCoT_predicted_answer": "Fr\u00e9d\u00e9ric Chopin", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
{"task_id": "0cebab5a088011ebbd6cac1f6bf848b6", "answer": "Hootenanny Hoot", "complexity_label": "C", "NoR_time_taken": "0.705", "IRCoT_time_taken": "283.8062283737024", "gold_answers": "[\"Snake'S Venom\"]", "NoR_predicted_answer": "Hootenanny Hoot", "IRCoT_predicted_answer": "Hootenanny Hoot", "NoR_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0", "IRCoT_evaluation_results": "em:0.0 f1:0.0 count:1 accuracy:0.0"}
