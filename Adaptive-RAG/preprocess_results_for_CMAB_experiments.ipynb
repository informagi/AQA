{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to preprocess the output files that we got from running individual agents to make it ready for CMAB and GPTSwarm experiments.\n",
    "\n",
    "We Get the 1) question_id, 2)question_text, 4) gold_answer, 5) predicted_answer, 6) evaluation_results, 7) complexity_label, 8) time_taken (and steps_taken) for each question in the train and test files and from the predictions of NoR, OneR and IRCoT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess 1\n",
    "Here we first extract some values (time taken, confidence scores, etc.) from the log files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [\"nor\", \"oner\", \"ircot\"]\n",
    "path_to_inference_log_files_for_test_data_for_each_agent = [\n",
    "   f\"../LOGS/test/{agent}_qa_flan_xl_test_aware_210_51.txt\" for agent in agents\n",
    "]\n",
    "\n",
    "path_to_inference_log_files_for_train_data_for_each_agent = [\n",
    "    f\"../LOGS/train/{agent}_qa_flan_xl_train_aware_210_51.txt\" for agent in agents\n",
    "]\n",
    "\n",
    "destination_folder = \"../Results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_file(filepath):\n",
    "    data_dict = {}\n",
    "    current_index = None\n",
    "    current_qid = None\n",
    "    current_sub_index = 0\n",
    "    sub_keys = ['Generated Texts:', 'Confidence Info:', 'Run Time in Seconds:']\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Index:\"):\n",
    "            current_index = int(line.split(\":\")[1].strip())\n",
    "            current_qid = None\n",
    "            current_sub_index = 0\n",
    "        elif line.startswith(\"Processing question:\"):\n",
    "            qid_start = line.find(\"QID:\") + 4\n",
    "            current_qid = line[qid_start:].strip()\n",
    "            if current_qid not in data_dict:\n",
    "                data_dict[current_qid] = {}\n",
    "        elif any(line.startswith(key) for key in sub_keys):\n",
    "            if current_qid is not None:\n",
    "                if current_sub_index not in data_dict[current_qid]:\n",
    "                    data_dict[current_qid][current_sub_index] = {\n",
    "                        'Generated Texts': '',\n",
    "                        'Confidence Info': '',\n",
    "                        'Run Time in Seconds': ''\n",
    "                    }\n",
    "                if line.startswith('Generated Texts:'):\n",
    "                    data_dict[current_qid][current_sub_index]['Generated Texts'] = line.split(\":\", 1)[1].strip()\n",
    "                elif line.startswith('Confidence Info:'):\n",
    "                    data_dict[current_qid][current_sub_index]['Confidence Info'] = line.split(\":\", 1)[1].strip()\n",
    "                elif line.startswith('Run Time in Seconds:'):\n",
    "                    data_dict[current_qid][current_sub_index]['Run Time in Seconds'] = line.split(\":\", 1)[1].strip()\n",
    "                    current_sub_index += 1\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def calculate_confidence_info(confidence_str):\n",
    "    # Extract probabilities\n",
    "    probs = re.findall(r\"'prob': ([\\d\\.]+)\", confidence_str)\n",
    "    if probs:\n",
    "        # convert strings to floats and calculate the average\n",
    "        return np.mean([float(prob) for prob in probs])\n",
    "    return 0.0\n",
    "\n",
    "def process_data(data_dict):\n",
    "    processed_data = {}\n",
    "    \n",
    "    for qid, subkeys in data_dict.items():\n",
    "        processed_qid = {\n",
    "            'number_of_subkeys': len(subkeys),\n",
    "            'subkey_details': {},\n",
    "            'total_run_time_in_seconds': 0,\n",
    "            'average_confidence_score_among_all_subkeys': [],\n",
    "            'average_confidence_score_of_the_last_subkey': 0\n",
    "        }\n",
    "        \n",
    "        for subkey_id, details in subkeys.items():\n",
    "            avg_confidence = calculate_confidence_info(details['Confidence Info'])\n",
    "            run_time = float(details['Run Time in Seconds'])\n",
    "            \n",
    "            processed_qid['subkey_details'][subkey_id] = {\n",
    "                'average_confidence_score': avg_confidence,\n",
    "                'run_time_in_seconds': run_time\n",
    "            }\n",
    "            processed_qid['total_run_time_in_seconds'] += run_time\n",
    "            processed_qid['average_confidence_score_among_all_subkeys'].append(avg_confidence)\n",
    "        \n",
    "        if processed_qid['average_confidence_score_among_all_subkeys']:\n",
    "            processed_qid['average_confidence_score_among_all_subkeys'] = np.mean(processed_qid['average_confidence_score_among_all_subkeys'])\n",
    "            last_subkey = list(subkeys.keys())[-1]\n",
    "            processed_qid['average_confidence_score_of_the_last_subkey'] = processed_qid['subkey_details'][last_subkey]['average_confidence_score']\n",
    "        \n",
    "        processed_data[qid] = processed_qid\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def write_to_jsonl(data, folder_path, filename):\n",
    "    file_path = f\"{folder_path}/{filename}\"\n",
    "    print(f\"Writing data to {file_path}\")\n",
    "    with open(file_path, 'w') as file:\n",
    "        for qid, details in data.items():\n",
    "            json_line = json.dumps({qid: details}) + '\\n'\n",
    "            file.write(json_line)\n",
    "    print(f\"Data successfully written to {file_path}\")\n",
    "\n",
    "def process_and_write(agent, log_file, data_type):\n",
    "    print(f\"Processing {data_type} log for {agent}: {log_file}\")\n",
    "    data_dict = parse_log_file(log_file)\n",
    "    processed_data = process_data(data_dict)\n",
    "    folder_path = f\"{destination_folder}/{data_type}/IndividualAgents/{agent}\"\n",
    "    file_name = f\"{agent}_qa_flan_xl_{data_type}_aware_210_51_processed.jsonl\"\n",
    "    write_to_jsonl(processed_data, folder_path, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test log for nor: ../LOGS/test/nor_qa_flan_xl_test_aware_210_51.txt\n",
      "Writing data to ../Results/test/IndividualAgents/nor/nor_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/test/IndividualAgents/nor/nor_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Processing train log for nor: ../LOGS/train/nor_qa_flan_xl_train_aware_210_51.txt\n",
      "Writing data to ../Results/train/IndividualAgents/nor/nor_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/train/IndividualAgents/nor/nor_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Processing for nor completed\n",
      "\n",
      "Processing test log for oner: ../LOGS/test/oner_qa_flan_xl_test_aware_210_51.txt\n",
      "Writing data to ../Results/test/IndividualAgents/oner/oner_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/test/IndividualAgents/oner/oner_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Processing train log for oner: ../LOGS/train/oner_qa_flan_xl_train_aware_210_51.txt\n",
      "Writing data to ../Results/train/IndividualAgents/oner/oner_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/train/IndividualAgents/oner/oner_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Processing for oner completed\n",
      "\n",
      "Processing test log for ircot: ../LOGS/test/ircot_qa_flan_xl_test_aware_210_51.txt\n",
      "Writing data to ../Results/test/IndividualAgents/ircot/ircot_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/test/IndividualAgents/ircot/ircot_qa_flan_xl_test_aware_210_51_processed.jsonl\n",
      "Processing train log for ircot: ../LOGS/train/ircot_qa_flan_xl_train_aware_210_51.txt\n",
      "Writing data to ../Results/train/IndividualAgents/ircot/ircot_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Data successfully written to ../Results/train/IndividualAgents/ircot/ircot_qa_flan_xl_train_aware_210_51_processed.jsonl\n",
      "Processing for ircot completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for agent, test_log_file, train_log_file in zip(agents, path_to_inference_log_files_for_test_data_for_each_agent, path_to_inference_log_files_for_train_data_for_each_agent):\n",
    "    process_and_write(agent, test_log_file, \"test\")\n",
    "    process_and_write(agent, train_log_file, \"train\")\n",
    "    print(f\"Processing for {agent} completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "output_folder = \"../Preprocessed_Data_for_CMAB\"\n",
    "\n",
    "\n",
    "# read the ORGINAL train and test files\n",
    "\n",
    "path_to_original_files = {\n",
    "    \"train\": \"../AQA_Data_Final/train_aware_210_51.jsonl\",\n",
    "    \"test\": \"../AQA_Data_Final/test_aware_210_51.jsonl\"\n",
    "}\n",
    "\n",
    "\n",
    "# read the PROCESSED PREDICTION FILES of NoR, OneR and IRCoT agents for the original train and test files\n",
    "\n",
    "path_to_processed_logs = {\n",
    "    \"test\": [\n",
    "        f\"../Results/test/IndividualAgents/{agent}/{agent}_qa_flan_xl_test_aware_210_51_processed.jsonl\" for agent in agents\n",
    "    ],\n",
    "    \"train\": [\n",
    "        f\"../Results/train/IndividualAgents/{agent}/{agent}_qa_flan_xl_train_aware_210_51_processed.jsonl\" for agent in agents\n",
    "    ]\n",
    "}\n",
    "\n",
    "path_to_predictions = {\n",
    "    \"test\": [\n",
    "        f\"../Results/test/IndividualAgents/{agent}/{agent}_qa_flan_xl_test_aware_210_51.json\" for agent in agents\n",
    "    ],\n",
    "    \"train\": [\n",
    "        f\"../Results/train/IndividualAgents/{agent}/{agent}_qa_flan_xl_train_aware_210_51.json\" for agent in agents\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# where we will save the processed data for CMAB\n",
    "output_folder = \"../Results/processed_data_for_CMAB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in the original train file: 210\n",
      "Number of questions in the original test file: 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'question_id': '5a7ca33f5542990527d554ee',\n",
       "  'question_text': \"Which restaurant chain is based further south, Pizza Fusion or Imo's Pizza?\",\n",
       "  'gold_answers': ['Pizza Fusion'],\n",
       "  'complexity_label': 'B'},\n",
       " {'question_id': 'single_nq_dev_2922',\n",
       "  'question_text': 'which is the eighth planet from the sun ( in order of increasing mean distance or semimajor axis )',\n",
       "  'gold_answers': ['Neptune'],\n",
       "  'complexity_label': 'B'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data_point = json.loads(line)\n",
    "            gold_answer_default = data_point[\"answers_objects\"][0][\"spans\"]\n",
    "            # Flatten the gold answers\n",
    "            # flattened_answers = [ans if isinstance(ans, str) else ''.join(ans) for ans in gold_answers]\n",
    "            \n",
    "            gold_answer = []\n",
    "            for answer in gold_answer_default:\n",
    "                if isinstance(answer, str):\n",
    "                    gold_answer.append(answer)\n",
    "                else:\n",
    "                    gold_answer.extend(answer)\n",
    "\n",
    "            data.append({\n",
    "                \"question_id\": data_point[\"question_id\"],\n",
    "                \"question_text\": data_point[\"question_text\"],\n",
    "                \"gold_answers\": gold_answer,\n",
    "                \"complexity_label\": data_point[\"complexity_label\"]\n",
    "            })\n",
    "    return data\n",
    "\n",
    "# Read the train and test data\n",
    "\n",
    "train_data = read_data(path_to_original_files[\"train\"])\n",
    "test_data = read_data(path_to_original_files[\"test\"])\n",
    "\n",
    "\n",
    "print(f\"Number of questions in the original train file: {len(train_data)}\")\n",
    "print(f\"Number of questions in the original test file: {len(test_data)}\")\n",
    "\n",
    "train_data[0], test_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AQA_final_eval import evaluate_single\n",
    "\n",
    "# now read the processed predictions for each agent for the train and test data and merge them with the original data and save them in the output folder\n",
    "\n",
    "def merger(path_to_original_file, processed_logs_file_paths, predictions_file_paths, destination_folder):\n",
    "    original_data = read_data(path_to_original_file)\n",
    "    processed_logs = {}\n",
    "    all_predictions = {}\n",
    "    for agent, processed_file, prediction_file in zip(agents, processed_logs_file_paths, predictions_file_paths):\n",
    "        print(f\"Agent: {agent}, Processed File: {processed_file}, Prediction File: {prediction_file}\")\n",
    "\n",
    "        with open(processed_file, \"r\") as f:\n",
    "            processed_data = {}\n",
    "            for line in f:\n",
    "                data_point = json.loads(line)\n",
    "                qid = list(data_point.keys())[0]\n",
    "                processed_data[qid] = data_point[qid]\n",
    "            processed_logs[agent] = processed_data\n",
    "        \n",
    "        with open(prediction_file, \"r\") as f:\n",
    "            predictions = json.load(f)\n",
    "            all_predictions[agent] = predictions\n",
    "\n",
    "    # merge the original data with the processed logs\n",
    "    merged_data = []\n",
    "    for data_point in original_data:\n",
    "        qid = data_point[\"question_id\"]\n",
    "        merged_point = {\n",
    "            \"question_id\": qid,\n",
    "            \"question_text\": data_point[\"question_text\"],\n",
    "            \"gold_answers\": data_point[\"gold_answers\"],\n",
    "            \"complexity_label\": data_point[\"complexity_label\"]\n",
    "        }\n",
    "        for agent in agents:\n",
    "            if qid in processed_logs[agent]:\n",
    "                merged_point[f\"{agent}_predicted_answer\"] = all_predictions[agent][qid]\n",
    "                merged_point[f\"{agent}_time_taken\"] = processed_logs[agent][qid][\"total_run_time_in_seconds\"]\n",
    "                merged_point[f\"{agent}_steps_taken\"] = processed_logs[agent][qid][\"number_of_subkeys\"]\n",
    "                merged_point[f\"{agent}_evaluation_results\"] = evaluate_single(merged_point[f\"{agent}_predicted_answer\"], merged_point[\"gold_answers\"])\n",
    "        merged_data.append(merged_point)\n",
    "\n",
    "    # save the merged data in a jsonl file\n",
    "    output_file_name = os.path.basename(path_to_original_file).replace(\".jsonl\", \"_complete.jsonl\")\n",
    "    output_file_path = os.path.join(destination_folder, output_file_name)\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        for data_point in merged_data:\n",
    "            f.write(json.dumps(data_point) + \"\\n\")\n",
    "    return merged_data\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: nor, Processed File: ../Results/test/IndividualAgents/nor/nor_qa_flan_xl_test_aware_210_51_processed.jsonl, Prediction File: ../Results/test/IndividualAgents/nor/nor_qa_flan_xl_test_aware_210_51.json\n",
      "Agent: oner, Processed File: ../Results/test/IndividualAgents/oner/oner_qa_flan_xl_test_aware_210_51_processed.jsonl, Prediction File: ../Results/test/IndividualAgents/oner/oner_qa_flan_xl_test_aware_210_51.json\n",
      "Agent: ircot, Processed File: ../Results/test/IndividualAgents/ircot/ircot_qa_flan_xl_test_aware_210_51_processed.jsonl, Prediction File: ../Results/test/IndividualAgents/ircot/ircot_qa_flan_xl_test_aware_210_51.json\n"
     ]
    }
   ],
   "source": [
    "merged_test_data = merger(path_to_original_files[\"test\"], path_to_processed_logs[\"test\"], path_to_predictions[\"test\"], output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 'single_nq_dev_2922',\n",
       " 'question_text': 'which is the eighth planet from the sun ( in order of increasing mean distance or semimajor axis )',\n",
       " 'gold_answers': ['Neptune'],\n",
       " 'complexity_label': 'B',\n",
       " 'nor_predicted_answer': 'Uranus',\n",
       " 'nor_time_taken': 2.038320779800415,\n",
       " 'nor_steps_taken': 1,\n",
       " 'nor_evaluation_results': {'em': 0.0, 'f1': 0.0, 'count': 1, 'accuracy': 0.0},\n",
       " 'oner_predicted_answer': 'Neptune',\n",
       " 'oner_time_taken': 6.091372489929199,\n",
       " 'oner_steps_taken': 1,\n",
       " 'oner_evaluation_results': {'em': 1.0,\n",
       "  'f1': 1.0,\n",
       "  'count': 1,\n",
       "  'accuracy': 1.0},\n",
       " 'ircot_predicted_answer': 'Neptune',\n",
       " 'ircot_time_taken': 1359.9865555763245,\n",
       " 'ircot_steps_taken': 11,\n",
       " 'ircot_evaluation_results': {'em': 1.0,\n",
       "  'f1': 1.0,\n",
       "  'count': 1,\n",
       "  'accuracy': 1.0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: nor, Processed File: ../Results/train/IndividualAgents/nor/nor_qa_flan_xl_train_aware_210_51_processed.jsonl, Prediction File: ../Results/train/IndividualAgents/nor/nor_qa_flan_xl_train_aware_210_51.json\n",
      "Agent: oner, Processed File: ../Results/train/IndividualAgents/oner/oner_qa_flan_xl_train_aware_210_51_processed.jsonl, Prediction File: ../Results/train/IndividualAgents/oner/oner_qa_flan_xl_train_aware_210_51.json\n",
      "Agent: ircot, Processed File: ../Results/train/IndividualAgents/ircot/ircot_qa_flan_xl_train_aware_210_51_processed.jsonl, Prediction File: ../Results/train/IndividualAgents/ircot/ircot_qa_flan_xl_train_aware_210_51.json\n"
     ]
    }
   ],
   "source": [
    "merged_train_data = merger(path_to_original_files[\"train\"], path_to_processed_logs[\"train\"], path_to_predictions[\"train\"], output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': '5a7ca33f5542990527d554ee',\n",
       " 'question_text': \"Which restaurant chain is based further south, Pizza Fusion or Imo's Pizza?\",\n",
       " 'gold_answers': ['Pizza Fusion'],\n",
       " 'complexity_label': 'B',\n",
       " 'nor_predicted_answer': \"Imo's Pizza\",\n",
       " 'nor_time_taken': 0.8518612384796143,\n",
       " 'nor_steps_taken': 1,\n",
       " 'nor_evaluation_results': {'em': 0.0, 'f1': 0.5, 'count': 1, 'accuracy': 0.0},\n",
       " 'oner_predicted_answer': 'Pizza Fusion',\n",
       " 'oner_time_taken': 5.093897819519043,\n",
       " 'oner_steps_taken': 1,\n",
       " 'oner_evaluation_results': {'em': 1.0,\n",
       "  'f1': 1.0,\n",
       "  'count': 1,\n",
       "  'accuracy': 1.0},\n",
       " 'ircot_predicted_answer': 'Pizza Fusion',\n",
       " 'ircot_time_taken': 84.7508134841919,\n",
       " 'ircot_steps_taken': 4,\n",
       " 'ircot_evaluation_results': {'em': 1.0,\n",
       "  'f1': 1.0,\n",
       "  'count': 1,\n",
       "  'accuracy': 1.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ircot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
